@article{Barbieri2001,
abstract = {A paradigm for constructing and analyzing non-Poisson stimulus-response models of neural spike train activity is presented. Inhomogeneous gamma (IG) and inverse Gaussian (IIG) probability models are constructed by generalizing the derivation of the inhomogeneous Poisson (IP) model from the exponential probability density. The resultant spike train models have Markov dependence. Quantile-quantile (Q-Q) plots and Kolmogorov-Smirnov (K-S) plots are developed based on the rate-rescaling theorem to assess model goodness-of-fit. The analysis also expresses the spike rate function of the neuron directly in terms of its interspike interval (ISI) distribution. The methods are illustrated with an analysis of 34 spike trains from rat CA1 hippocampal pyramidal neurons recorded while the animal executed a behavioral task. The stimulus in these experiments is the animal's position in its environment and the response is the neural spiking activity. For all 34 pyramidal cells, the IG and IIG models gave better fits to the spike trains than the IP. The IG model more accurately described the frequency of longer ISIs, whereas the IIG model gave the best description of the burst frequency, i.e. ISIs≤20 ms. The findings suggest that bursts are a significant component of place cell spiking activity even when position and the background variable, theta phase, are taken into account. Unlike the Poisson model, the spatial and temporal rate maps of the IG and IIG models depend directly on the spiking history of the neurons. These rate maps are more physiologically plausible since the interaction between space and time determines local spiking propensity. While this statistical paradigm is being developed to study information encoding by rat hippocampal neurons, the framework should be applicable to stimulus-response experiments performed in other neural systems. Copyright {\textcopyright} 2001 Elsevier Science B.V.},
author = {Barbieri, Riccardo and Quirk, Michael C and Frank, Loren M and Wilson, Matthew A and Brown, Emery N},
doi = {10.1016/S0165-0270(00)00344-7},
issn = {01650270},
journal = {Journal of Neuroscience Methods},
keywords = {Hippocampal place cells,Inhomogeneous Poisson process,Inhomogeneous gamma process,Inhomogeneous inverse Gaussian process,Interspike interval distributions,Kolmogorov-Smirnov plots,Markov models,Quantile-quantile plots,Rate-rescaling theorem},
month = {jan},
number = {1},
pages = {25--37},
pmid = {11166363},
title = {{Construction and analysis of non-Poisson stimulus-response models of neural spiking activity}},
volume = {105},
year = {2001}
}
@article{Ghanbari2019,
abstract = {Objective. Neural responses to repeated presentations of an identical stimulus often show substantial trial-To-Trial variability. How the mean firing rate varies in response to different stimuli or during different movements (tuning curves) has been extensively modeled in a wide variety of neural systems. However, the variability of neural responses can also have clear tuning independent of the tuning in the mean firing rate. This suggests that the variability could contain information regarding the stimulus/movement beyond what is encoded in the mean firing rate. Here we demonstrate how taking variability into account can improve neural decoding. Approach. In a typical neural coding model spike counts are assumed to be Poisson with the mean response depending on an external variable, such as a stimulus or movement. Bayesian decoding methods then use the probabilities under these Poisson tuning models (the likelihood) to estimate the probability of each stimulus given the spikes on a given trial (the posterior). However, under the Poisson model, spike count variability is always exactly equal to the mean (Fano factor = 1). Here we use two alternative models-the Conway-Maxwell-Poisson (CMP) model and negative binomial (NB) model-to more flexibly characterize how neural variability depends on external stimuli. These models both contain the Poisson distribution as a special case but have an additional parameter that allows the variance to be greater than the mean (Fano factor > 1) or, for the CMP model, less than the mean (Fano factor < 1). Main results. We find that neural responses in primary motor (M1), visual (V1), and auditory (A1) cortices have diverse tuning in both their mean firing rates and response variability. Across cortical areas, we find that Bayesian decoders using the CMP or NB models improve stimulus/movement estimation accuracy by 4%-12% compared to the Poisson model. Significance. Moreover, the uncertainty of the non-Poisson decoders more accurately reflects the magnitude of estimation errors. In addition to tuning curves that reflect average neural responses, stimulus-dependent response variability may be an important aspect of the neural code. Modeling this structure could, potentially, lead to improvements in brain machine interfaces.},
author = {Ghanbari, Abed and Lee, Christopher M. and Read, Heather L. and Stevenson, Ian H.},
doi = {10.1088/1741-2552/ab3a68},
issn = {17412552},
journal = {Journal of Neural Engineering},
keywords = {generalized linear model,neural coding,neural variability},
number = {6},
pmid = {31404915},
title = {{Modeling stimulus-dependent variability improves decoding of population neural responses}},
volume = {16},
year = {2019}
}
@article{Kelly2010,
abstract = {Multineuronal recordings have revealed that neurons in primary visual cortex (V1) exhibit coordinated fluctuations of spiking activity in the absence and in the presence of visual stimulation. From the perspective of understanding a single cell's spiking activity relative to a behavior or stimulus, these network fluctuations are typically considered to be noise. We show that these events are highly correlated with another commonly recorded signal, the local field potential (LFP), and are also likely related to global network state phenomena which have been observed in a number of neural systems. Moreover, we show that attributing a component of cell firing to these network fluctuations via explicit modeling of the LFP improves the recovery of cell properties. This suggests that the impact of network fluctuations may be estimated using the LFP, and that a portion of this network activity is unrelated to the stimulus and instead reflects ongoing cortical activity. Thus, the LFP acts as an easily accessible bridge between the network state and the spiking activity. {\textcopyright} Springer Science+Business Media, LLC 2010.},
author = {Kelly, Ryan C. and Smith, Matthew A. and Kass, Robert E. and Lee, Tai Sing},
doi = {10.1007/s10827-009-0208-9},
issn = {09295313},
journal = {Journal of Computational Neuroscience},
keywords = {Correlation,Decoding,Local field potential,Multielectrode array,Network state,Population coding,Spontaneous activity},
month = {dec},
number = {3},
pages = {567--579},
pmid = {20094906},
publisher = {J Comput Neurosci},
title = {{Local field potentials indicate network state and account for neuronal response variability}},
url = {https://pubmed.ncbi.nlm.nih.gov/20094906/},
volume = {29},
year = {2010}
}
@article{Rokni2007,
author = {Rokni, U and Richardson, A G and Bizzi, E and Seung, H S},
journal = {Neuron},
number = {4},
pages = {653--666},
title = {{Motor learning with unstable neural representations}},
volume = {54},
year = {2007}
}
@article{Churchland2010,
abstract = {Neural responses are typically characterized by computing the mean firing rate, but response variability can exist across trials. Many studies have examined the effect of a stimulus on the mean response, but few have examined the effect on response variability. We measured neural variability in 13 extracellularly recorded datasets and one intracellularly recorded dataset from seven areas spanning the four cortical lobes in monkeys and cats. In every case, stimulus onset caused a decline in neural variability. This occurred even when the stimulus produced little change in mean firing rate. The variability decline was observed in membrane potential recordings, in the spiking of individual neurons and in correlated spiking variability measured with implanted 96-electrode arrays. The variability decline was observed for all stimuli tested, regardless of whether the animal was awake, behaving or anaesthetized. This widespread variability decline suggests a rather general property of cortex, that its state is stabilized by an input. {\textcopyright} 2010 Nature America, Inc. All rights reserved.},
author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew a and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V},
doi = {10.1038/nn.2501},
isbn = {1546-1726 (Electronic)\n1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {3},
pages = {369--378},
pmid = {20173745},
publisher = {Nature Publishing Group},
title = {{Stimulus onset quenches neural variability: A widespread cortical phenomenon}},
volume = {13},
year = {2010}
}

@article{Paninski2010,
author = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel Gil and Koyama, Shinsuke and Rahnama Rad, Kamiar and Vidne, Michael and Vogelstein, Joshua and Wu, Wei},
title = {A New Look at State-Space Models for Neural Data},
year = {2010},
issue_date = {August 2010},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {29},
number = {1–2},
issn = {0929-5313},
url = {https://doi.org/10.1007/s10827-009-0179-x},
doi = {10.1007/s10827-009-0179-x},
abstract = {State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates.},
journal = {J. Comput. Neurosci.},
month = {aug},
pages = {107–126},
numpages = {20},
keywords = {Hidden Markov model, Tridiagonal matrix, Neural coding, State-space models}
}
@article{Steinmetz2021,
abstract = {Measuring the dynamics of neural processing across time scales requires following the spiking of thousands of individual neurons over milliseconds and months. To address this need, we introduce the Neuropixels 2.0 probe together with newly designed analysis algorithms. The probe has more than 5000 sites and is miniaturized to facilitate chronic implants in small mammals and recording during unrestrained behavior. High-quality recordings over long time scales were reliably obtained in mice and rats in six laboratories. Improved site density and arrangement combined with newly created data processing methods enable automatic post hoc correction for brain movements, allowing recording from the same neurons for more than 2 months. These probes and algorithms enable stable recordings from thousands of sites during free behavior, even in small animals such as mice.},
author = {Steinmetz, Nicholas A. and Aydin, Cagatay and Lebedeva, Anna and Okun, Michael and Pachitariu, Marius and Bauza, Marius and Beau, Maxime and Bhagat, Jai and B{\"{o}}hm, Claudia and Broux, Martijn and Chen, Susu and Colonell, Jennifer and Gardner, Richard J. and Karsh, Bill and Kloosterman, Fabian and Kostadinov, Dimitar and Mora-Lopez, Carolina and O'Callaghan, John and Park, Junchol and Putzeys, Jan and Sauerbrei, Britton and van Daal, Rik J.J. and Vollan, Abraham Z. and Wang, Shiwei and Welkenhuysen, Marleen and Ye, Zhiwen and Dudman, Joshua T. and Dutta, Barundeb and Hantman, Adam W. and Harris, Kenneth D. and Lee, Albert K. and Moser, Edvard I. and O'Keefe, John and Renart, Alfonso and Svoboda, Karel and H{\"{a}}usser, Michael and Haesler, Sebastian and Carandini, Matteo and Harris, Timothy D.},
doi = {10.1126/science.abf4588},
issn = {10959203},
journal = {Science},
month = {apr},
number = {6539},
pmid = {33859006},
publisher = {American Association for the Advancement of Science},
title = {{Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings}},
volume = {372},
year = {2021}
}
@article{Lesica2007,
abstract = {In this study, we characterize the adaptation of neurons in the cat lateral geniculate nucleus to changes in stimulus contrast and correlations. By comparing responses to high- and low-contrast natural scene movie and white noise stimuli, we show that an increase in contrast or correlations results in receptive fields with faster temporal dynamics and stronger antagonistic surrounds, as well as decreases in gain and selectivity. We also observe contrast- and correlation-induced changes in the reliability and sparseness of neural responses. We find that reliability is determined primarily by processing in the receptive field (the effective contrast of the stimulus), while sparseness is determined by the interactions between several functional properties. These results reveal a number of adaptive phenomena and suggest that adaptation to stimulus contrast and correlations may play an important role in visual coding in a dynamic natural environment. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Lesica, Nicholas A. and Jin, Jianzhong and Weng, Chong and Yeh, Chun I. and Butts, Daniel A. and Stanley, Garrett B. and Alonso, Jose Manuel},
doi = {10.1016/j.neuron.2007.07.013},
isbn = {0896-6273 (Print)\r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
keywords = {SYSNEURO},
number = {3},
pages = {479--491},
pmid = {17678859},
title = {{Adaptation to Stimulus Contrast and Correlations during Natural Visual Stimulation}},
volume = {55},
year = {2007}
}
@article{Chestek2007,
abstract = {Some movements that animals and humans make are highly stereotyped, repeated with little variation. The patterns of neural activity associated with repeats of a movement may be highly similar, or the same movement may arise from different patterns of neural activity, if the brain exploits redundancies in the neural projections to muscles. We examined the stability of the relationship between neural activity and behavior. We asked whether the variability in neural activity that we observed during repeated reaching was consistent with a noisy but stable relationship, or with a changing relationship, between neural activity and behavior. Monkeys performed highly similar reaches under tight behavioral control, while many neurons in the dorsal aspect of premotor cortex and the primary motor cortex were simultaneously monitored for several hours. Neural activity was predominantly stable over time in all measured properties: firing rate, directional tuning, and contribution to a decoding model that predicted kinematics from neural activity. The small changes in neural activity that we did observe could be accounted for primarily by subtle changes in behavior. We conclude that the relationship between neural activity and practiced behavior is reasonably stable, at least on timescales of minutes up to 48 h. This finding has significant implications for the design of neural prosthetic systems because it suggests that device recalibration need not be overly frequent, It also has implications for studies of neural plasticity because a stable baseline permits identification of nonstationary shifts. Copyright {\textcopyright} 2007 Society for Neuroscience.},
author = {Chestek, Cynthia A and Batista, Aaron P and Santhanam, Gopal and Yu, Byron M and Afshar, Afsheen and Cunningham, John P and Gilja, Vikash and Ryu, Stephen I and Churchland, Mark M and Shenoy, Krishna V},
doi = {10.1523/JNEUROSCI.0959-07.2007},
isbn = {1529-2401 (Electronic)},
issn = {02706474},
journal = {Journal of Neuroscience},
keywords = {Arm,Brain machine interface,Decoding,Macaque,Multielectrode array,Premotor},
language = {eng},
number = {40},
pages = {10742--10750},
pmid = {17913908},
title = {{Single-neuron stability during repeated reaching in macaque premotor cortex}},
volume = {27},
year = {2007}
}
@article{Stevenson2011a,
abstract = {In systems neuroscience, neural activity that represents movements or sensory stimuli is often characterized by spatial tuning curves that may change in response to training, attention, altered mechanics, or the passage of time. A vital step in determining whether tuning curves change is accounting for estimation uncertainty due to measurement noise. In this study, we address the issue of tuning curve stability using methods that take uncertainty directly into account. We analyze data recorded from neurons in primary motor cortex using chronically implanted, multielectrode arrays in four monkeys performing center-out reaching. With the use of simulations, we demonstrate that under typical experimental conditions, the effect of neuronal noise on estimated preferred direction can be quite large and is affected by both the amount of data and the modulation depth of the neurons. In experimental data, we find that after taking uncertainty into account using bootstrapping techniques, the majority of neurons appears to be very stable on a timescale of minutes to hours. Lastly, we introduce adaptive filtering methods to explicitly model dynamic tuning curves. In contrast to several previous findings suggesting that tuning curves may be in constant flux, we conclude that the neural representation of limb movement is, on average, quite stable and that impressions to the contrary may be largely the result of measurement noise. {\textcopyright} 2011 the American Physiological Society.},
author = {Stevenson, Ian H. and Cherian, Anil and London, Brian M. and Sachs, Nicholas A. and Lindberg, Eric and Reimer, Jacob and Slutzky, Marc W. and Hatsopoulos, Nicholas G. and Miller, Lee E. and Kording, Konrad P.},
doi = {10.1152/jn.00626.2010},
issn = {00223077},
journal = {Journal of Neurophysiology},
keywords = {Neurons,Poisson noise,Primary motor cortex,Sensory stimuli,Spatial tuning curves,Tuning curves},
month = {aug},
number = {2},
pages = {764--774},
pmid = {21613593},
publisher = {J Neurophysiol},
title = {{Statistical assessment of the stability of neural movement representations}},
url = {https://pubmed.ncbi.nlm.nih.gov/21613593/},
volume = {106},
year = {2011}
}
@article{Shmueli2005,
abstract = {A useful discrete distribution (the Conway-Maxwell-Poisson distribution) is revived and its statistical and probabilistic properties are introduced and explored. This distribution is a two-parameter extension of the Poisson distribution that generalizes some well-known discrete distributions (Poisson, Bernoulli and geometric). It also leads to the generalization of distributions derived from these discrete distributions (i.e. the binomial and negative binomial distributions). We describe three methods for estimating the parameters of the Conway-Maxwell-Poisson distribution. The first is a fast simple weighted least squares method, which leads to estimates that are sufficiently accurate for practical purposes. The second method, using maximum likelihood, can be used to refine the initial estimates. This method requires iterations and is more computationally intensive. The third estimation method is Bayesian. Using the conjugate prior, the posterior density of the parameters of the Conway-Maxwell-Poisson distribution is easily computed. It is a flexible distribution that can account for overdispersion or underdispersion that is commonly encountered in count data. We also explore two sets of real world data demonstrating the flexibility and elegance of the Conway-Maxwell-Poisson distribution in fitting count data which do not seem to follow the Poisson distribution.},
author = {Shmueli, Galit and Minka, Thomas P. and Kadane, Joseph B. and Borle, Sharad and Boatwright, Peter},
doi = {10.1111/J.1467-9876.2005.00474.X},
issn = {1467-9876},
journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
keywords = {Conjugate family,Conway,Estimation,Exponential family,Maxwell,Overdispersion,Poisson distribution,Underdispersion},
month = {jan},
number = {1},
pages = {127--142},
publisher = {John Wiley & Sons, Ltd},
title = {{A useful distribution for fitting discrete data: revival of the Conway–Maxwell–Poisson distribution}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9876.2005.00474.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9876.2005.00474.x https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9876.2005.00474.x},
volume = {54},
year = {2005}
}
@article{Macke2011,
abstract = {Neurons in the neocortex code and compute as part of a locally interconnected population. Large-scale multi-electrode recording makes it possible to access these population processes empirically by fitting statistical models to unaveraged data. What statistical structure best describes the concurrent spiking of cells within a local network? We argue that in the cortex, where firing exhibits extensive correlations in both time and space and where a typical sample of neurons still reflects only a very small fraction of the local population, the most appropriate model captures shared variability by a low-dimensional latent process evolving with smooth dynamics, rather than by putative direct coupling. We test this claim by comparing a latent dynamical model with realistic spiking observations to coupled gen-eralised linear spike-response models (GLMs) using cortical recordings. We find that the latent dynamical approach outperforms the GLM in terms of goodness-of-fit, and reproduces the temporal correlations in the data more accurately. We also compare models whose observations models are either derived from a Gaussian or point-process models, finding that the non-Gaussian model provides slightly better goodness-of-fit and more realistic population spike counts.},
author = {Macke, Jakob H. and Buesing, Lars and Cunningham, John P. and Yu, Byron M. and Shenoy, Krishna V. and Sahani, Maneesh},
journal = {Advances in Neural Information Processing Systems},
title = {{Empirical models of spiking in neural populations}},
volume = {24},
year = {2011}
}
@article{Chatla2018,
abstract = {The Conway–Maxwell–Poisson (CMP) or COM–Poisson regression is a popular model for count data due to its ability to capture both under dispersion and over dispersion. However, CMP regression is limited when dealing with complex nonlinear relationships. With today's wide availability of count data, especially due to the growing collection of data on human and social behavior, there is need for count data models that can capture complex nonlinear relationships. One useful approach is additive models; but, there has been no additive model implementation for the CMP distribution. To fill this void, we first propose a flexible estimation framework for CMP regression based on iterative reweighed least squares (IRLS) and then extend this model to allow for additive components using a penalized splines approach. Because the CMP distribution belongs to the exponential family, convergence of IRLS is guaranteed under some regularity conditions. Further, it is also known that IRLS provides smaller standard errors compared to gradient-based methods. We illustrate the usefulness of this approach through extensive simulation studies and using real data from a bike sharing system in Washington, DC.},
author = {Chatla, Suneel Babu and Shmueli, Galit},
doi = {10.1016/J.CSDA.2017.11.011},
issn = {0167-9473},
journal = {Computational Statistics and Data Analysis},
keywords = {IRLS,Over and under dispersion,P-IRLS,Penalized splines,Time series},
month = {may},
pages = {71--88},
publisher = {North-Holland},
title = {{Efficient estimation of COM–Poisson regression and a generalized additive model}},
volume = {121},
year = {2018}
}
@article{Wei2021,
abstract = {Synapses change on multiple timescales, ranging from milliseconds to minutes, due to a combination of both short- and long-term plasticity. Here we develop an extension of the common generalized linear model to infer both short- and long-term changes in the coupling between a pre- and postsynaptic neuron based on observed spiking activity. We model short-term synaptic plasticity using additive effects that depend on the presynaptic spike timing, and we model long-term changes in both synaptic weight and baseline firing rate using point process adaptive smoothing. Using simulations, we first show that this model can accurately recover time-varying synaptic weights (1) for both depressing and facilitating synapses, (2) with a variety of long-term changes (including realistic changes, such as due to STDP), (3) with a range of pre and postsynaptic firing rates, and (4) for both excitatory and inhibitory synapses. We then apply our model to two experimentally recorded putative synaptic connections. We find that simultaneously tracking fast changes in synaptic weights, slow changes in synaptic weights, and unexplained variations in baseline firing is essential. Omitting any one of these factors can lead to spurious inferences for the others. Altogether, this model provides a flexible framework for tracking short- and long-term variation in spike transmission.},
archivePrefix = {arXiv},
arxivId = {2102.01803},
author = {Wei, Ganchao and Stevenson, Ian H.},
doi = {10.1162/NECO_A_01426},
eprint = {2102.01803},
issn = {1530-888X},
journal = {Neural computation},
keywords = {Ganchao Wei,Ian H Stevenson,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-P.H.S.,PubMed Abstract,Research Support,U.S. Gov't,doi:10.1162/neco_a_01426,pmid:34530452},
month = {sep},
number = {10},
pages = {2682--2709},
pmid = {34530452},
publisher = {Neural Comput},
title = {{Tracking Fast and Slow Changes in Synaptic Weights From Simultaneously Observed Pre- and Postsynaptic Spiking}},
url = {https://pubmed.ncbi.nlm.nih.gov/34530452/},
volume = {33},
year = {2021}
}
@article{Fenton1998,
abstract = {The idea that the rat hippocampus stores a map of space is based on the existence of 'place cells' that show 'location-specific' firing. The discharge of place cells is confined with remarkable precision to a cell- specific part of the environment called the cell's 'firing field.' We demonstrate here that firing is not nearly as reliable in the time domain as in the positional domain. Discharge during passes through the firing field was compared with a model with Poisson variance of the location-specific firing determined by the time-averaged positional firing rate distribution. Place cells characteristically fire too little or too much compared with expectations from the random model. This fundamental property of place cells is referred to as 'excess firing variance' and has three main implications: (i) Place cell discharge is not only driven by the summation of many small, asynchronous excitatory synaptic inputs. (ii) Place cell discharge may encode a signal in addition to the current head location. (iii) The excess firing variance helps explain why the errors in computing the rat's position from the simultaneous activity of many place cells are large.},
author = {Fenton, Andr{\'{e}} A. and Muller, Robert U.},
doi = {10.1073/pnas.95.6.3182},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {6},
pages = {3182--3187},
pmid = {9501237},
title = {{Place cell discharge is extremely variable during individual passes of the rat through the firing field}},
volume = {95},
year = {1998}
}
@article{Smith2008,
abstract = {The spiking activity of cortical neurons is correlated. For instance, trial-to-trial fluctuations in response strength are shared between neurons, and spikes often occur synchronously. Understanding the properties and mechanisms that generate these forms of correlation is critical for determining their role in cortical processing. We therefore investigated the spatial extent and functional specificity of correlated spontaneous and evoked activity. Because feedforward, recurrent, and feedback pathways have distinct extents and specificity, we reasoned that these measurements could elucidate the contribution of each type of input. We recorded single unit activity with microelectrode arrays which allowed us to measure correlation in many hundreds of pairings, across a large range of spatial scales. Our data show that correlated evoked activity is generated by two mechanisms that link neurons with similar orientation preferences on different spatial scales: one with high temporal precision and a limited spatial extent (∼3 mm), and a second that gives rise to correlation on a slow time scale and extends as far as we were able to measure (10 mm). The former is consistent with common input provided by horizontal connections; the latter likely involves feedback from extrastriate cortex. Spontaneous activity was correlated over a similar spatial extent, but approximately twice as strongly as evoked activity. Visual stimuli thus caused a substantial decrease in correlation, particularly at response onset. These properties and the circuit mechanism they imply provide new constraints on the functional role that correlation may play in visual processing. Copyright {\textcopyright} 2008 Society for Neuroscience.},
author = {Smith, Matthew A. and Kohn, Adam},
doi = {10.1523/JNEUROSCI.2929-08.2008},
issn = {02706474},
journal = {Journal of Neuroscience},
keywords = {Array,Cross-correlogram,Multielectrode recordings,Noise correlation,Population coding,Signal correlation,Spontaneous activity,Synchrony},
month = {nov},
number = {48},
pages = {12591--12603},
pmid = {19036953},
title = {{Spatial and temporal scales of neuronal correlation in primary visual cortex}},
volume = {28},
year = {2008}
}
@article{Churchland2011,
abstract = {Traditionally, insights into neural computation have been furnished by averaged firing rates from many stimulus repetitions or trials. We pursue an analysis of neural response variance to unveil neural computations that cannot be discerned from measures of average firing rate. We analyzed single-neuron recordings from the lateral intraparietal area (LIP), during a perceptual decision-making task. Spike count variance was divided into two components using the law of total variance for doubly stochastic processes: (1) variance of counts that would be produced by a stochastic point process with a given rate, and loosely (2) the variance of the rates that would produce those counts (i.e., " conditional expectation" ). The variance and correlation of the conditional expectation exposed several neural mechanisms: mixtures of firing rate states preceding the decision, accumulation of stochastic " evidence" during decision formation, and a stereotyped response at decision end. These analyses help to differentiate among several alternative decision-making models. {\textcopyright} 2011 Elsevier Inc.},
author = {Churchland, Anne K and Kiani, R. and Chaudhuri, R. and Wang, Xiao Jing and Pouget, Alexandre and Shadlen, M. N.},
doi = {10.1016/j.neuron.2010.12.037},
isbn = {1097-4199 (Electronic)\r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {4},
pages = {818--831},
pmid = {21338889},
title = {{Variance as a Signature of Neural Computations during Decision Making}},
volume = {69},
year = {2011}
}
@article{Gupta2014,
abstract = {In this paper, we further study the Conway–Maxwell Poisson distribution having one more parameter than the Poisson distribution and compare it with the Poisson distribution with respect to some stochastic orderings used in reliability theory. Likelihood ratio test and the score test are developed to test the importance of this additional parameter. Simulation studies are carried out to examine the performance of the two tests. Two examples are presented, one showing overdispersion and the other showing underdispersion, to illustrate the procedure. It is shown that the COM-Poisson model fits better than the generalized Poisson distribution.},
author = {Gupta, Ramesh C. and Sim, S. Z. and Ong, S. H.},
doi = {10.1007/S10182-014-0226-4/TABLES/7},
issn = {1863818X},
journal = {AStA Advances in Statistical Analysis},
keywords = {Failure rate,Overdispersion,Score test,Stochastic comparisons,Underdispersion},
month = {oct},
number = {4},
pages = {327--343},
publisher = {Springer Verlag},
title = {{Analysis of discrete data by Conway–Maxwell Poisson distribution}},
url = {https://link.springer.com/article/10.1007/s10182-014-0226-4},
volume = {98},
year = {2014}
}
@article{Dickey2009,
abstract = {The use of chronic intracortical multielectrode arrays has become increasingly prevalent in neurophysiological experiments. However, it is not obvious whether neuronal signals obtained over multiple recording sessions come from the same or different neurons. Here, we develop a criterion to assess single-unit stability by measuring the similarity of 1) average spike waveforms and 2) interspike interval histograms (ISIHs). Neuronal activity was recorded from four Utah arrays implanted in primary motor and premotor cortices in three rhesus macaque monkeys during 10 recording sessions over a 15- to 17-day period. A unit was defined as stable through a given day if the stability criterion was satisfied on all recordings leading up to that day. We found that 57% of the original units were stable through 7 days, 43% were stable through 10 days, and 39% were stable through 15 days. Moreover, stable units were more likely to remain stable in subsequent recording sessions (i.e., 89% of the neurons that were stable through four sessions remained stable on the fifth). Using both waveform and ISIH data instead of just waveforms improved performance by reducing the number of false positives. We also demonstrate that this method can be used to track neurons across days, even during adaptation to a visuomotor rotation. Identifying a stable subset of neurons should allow the study of long-term learning effects across days and has practical implications for pooling of behavioral data across days and for increasing the effectiveness of brain-machine interfaces. Copyright {\textcopyright} 2009 The American Physiological Society.},
author = {Dickey, Adam S and Suminski, Aaron and Amit, Yali and Hatsopoulos, Nicholas G},
doi = {10.1152/jn.90920.2008},
isbn = {0022-3077},
issn = {00223077},
journal = {Journal of Neurophysiology},
number = {2},
pages = {1331--1339},
pmid = {19535480},
publisher = {Am Physiological Soc},
title = {{Single-unit stability using chronically implanted multielectrode arrays}},
volume = {102},
year = {2009}
}
@article{DeWeese1998,
abstract = {It has long been recognized that sensory systems adapt to their inputs. Here we formulate the problem of optimal variance estimation for a broad class of nonstationary signals. We show that under weak assumptions, the Bayesian optimal causal variance estimate shows asymmetric dynamics: an abrupt increase in variance is more readily detectable than an abrupt decrease. By contrast, optimal adaptation to the mean displays symmetric dynamics when the variance is held fixed. After providing several empirical examples and a simple intuitive argument for our main result, we prove that optimal adaptation is asymmetrical in a broad class of model environments. This observation makes specific and falsifiable predictions about the time course of adaptation in neurons probed with certain stimulus ensembles.},
author = {DeWeese, Michael and Zador, Anthony},
doi = {10.1162/089976698300017403},
issn = {08997667},
journal = {Neural Computation},
number = {5},
pages = {1179--1202},
publisher = {MIT Press},
title = {{Asymmetric Dynamics in Optimal Variance Adaptation}},
volume = {10},
year = {1998}
}
@article{Brown2001,
abstract = {Neural receptive fields are plastic: with experience, neurons in many brain regions change their spiking responses to relevant stimuli. Analysis of receptive field plasticity from experimental measurements is crucial for understanding how neural systems adapt their representations of relevant biological information. Current analysis methods using histogram estimates of spike rate functions in nonoverlapping temporal windows do not track the evolution of receptive field plasticity on a fine time scale. Adaptive signal processing is an established engineering paradigm for estimating time-varying system parameters from experimental measurements. We present an adaptive filter algorithm for tracking neural receptive field plasticity based on point process models of spike train activity. We derive an instantaneous steepest descent algorithm by using as the criterion function the instantaneous log likelihood of a point process spike train model. We apply the point process adaptive filter algorithm in a study of spatial (place) receptive field properties of simulated and actual spike train data from rat CA1 hippocampal neurons. A stability analysis of the algorithm is sketched in the [Appendix][1]. The adaptive algorithm can update the place field parameter estimates on a millisecond time scale. It reliably tracked the migration, changes in scale, and changes in maximum firing rate characteristic of hippocampal place fields in a rat running on a linear track. Point process adaptive filtering offers an analytic method for studying the dynamics of neural receptive fields.

 [1]: #app-1},
author = {Brown, Emery N. and Nguyen, David P. and Frank, Loren M. and Wilson, Matthew A. and Solo, Victor},
doi = {10.1073/PNAS.201409398},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {oct},
number = {21},
pages = {12261--12266},
pmid = {11593043},
publisher = {National Academy of Sciences},
title = {{An analysis of neural receptive field plasticity by point process adaptive filtering}},
url = {https://www.pnas.org/content/98/21/12261},
volume = {98},
year = {2001}
}
@article{Sellers2010,
author = {Kimberly F. Sellers and Galit Shmueli},
title = {{A flexible regression model for count data}},
volume = {4},
journal = {The Annals of Applied Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {943 -- 961},
keywords = {Conway–Maxwell-Poisson (COM-Poisson) distribution, dispersion, generalized linear models (GLM), generalized Poisson},
year = {2010},
doi = {10.1214/09-AOAS306},
URL = {https://doi.org/10.1214/09-AOAS306}
}
@article{Stevenson2016,
abstract = {A key observation in systems neuroscience is that neural responses vary, even in controlled settings where stimuli are held constant. Many statistical models assume that trial-to-trial spike count variability is Poisson, but there is considerable evidence that neurons can be substantially more or less variable than Poisson depending on the stimuli, attentional state, and brain area. Here we examine a set of spike count models based on the Conway-Maxwell-Poisson (COM-Poisson) distribution that can flexibly account for both over- and under-dispersion in spike count data. We illustrate applications of this noise model for Bayesian estimation of tuning curves and peri-stimulus time histograms. We find that COM-Poisson models with group/observation-level dispersion, where spike count variability is a function of time or stimulus, produce more accurate descriptions of spike counts compared to Poisson models as well as negative-binomial models often used as alternatives. Since dispersion is one determinant of parameter standard errors, COM-Poisson models are also likely to yield more accurate model comparison. More generally, these methods provide a useful, model-based framework for inferring both the mean and variability of neural responses.},
author = {Stevenson, Ian H.},
doi = {10.1007/s10827-016-0603-y},
issn = {15736873},
journal = {Journal of Computational Neuroscience},
keywords = {Conway-Maxwell-Poisson,Poisson,Spike count variability,Tuning curves},
month = {aug},
number = {1},
pages = {29--43},
pmid = {27008191},
publisher = {Springer New York LLC},
title = {{Flexible models for spike count data with both over- and under- dispersion}},
url = {https://link.springer.com/article/10.1007/s10827-016-0603-y},
volume = {41},
year = {2016}
}
@misc{Kohn2016,
author = {Kohn, A. and Smith, M.A.},
booktitle = {CRCNS.org},
title = {{Utah array extracellular recordings of spontaneous and visually evoked activity from anesthetized macaque primary visual cortex (V1)}},
url = {http://dx.doi.org/10.6080/K0NC5Z4X},
year = {2016}
}
@article{Eden2004,
abstract = {Neural receptive fields are dynamic in that with experience, neurons change their spiking responses to relevant stimuli. To understand how neural systems adapt the irrepresentations of biological information, analyses of receptive field plasticity from experimental measurements are crucial. Adaptive signal processing, the well-established engineering discipline for characterizing the temporal evolution of system parameters, suggests a framework for studying the plasticity of receptive fields. We use the Bayes' rule Chapman-Kolmogorov paradigm with a linear state equation and point process observation models to derive adaptive filters appropriate for estimation from neural spike trains. We derive point process filter analogues of the Kalman filter, recursive least squares, and steepest-descent algorithms and describe the properties of these new fil-ters. We illustrate our algorithms in two simulated data examples. The first is a study of slow and rapid evolution of spatial receptive fields in hippocampal neurons. The second is an adaptive decoding study in which a signal is decoded from ensemble neural spiking activity as the recep-tive fields of the neurons in the ensemble evolve. Our results provide a paradigm for adaptive estimation for point process observations and suggest a practical approach for constructing filtering algorithms to track neural receptive field dynamics on a millisecond timescale.},
annote = {doi: 10.1162/089976604773135069},
author = {Eden, Uri T and Frank, Loren M. and Barbieri, Riccardo and Solo, Victor and Brown, Emery N.},
doi = {10.1162/089976604773135069},
issn = {0899-7667},
journal = {Neural Computation},
month = {may},
number = {5},
pages = {971--998},
publisher = {MIT Press},
title = {{Dynamic Analysis of Neural Encoding by Point Process Adaptive Filtering}},
url = {https://doi.org/10.1162/089976604773135069},
volume = {16},
year = {2004}
}
@article{Gaunt2019,
abstract = {The Conway-Maxwell-Poisson distribution is a two-parameter generalization of the Poisson distribution that can be used to model data that are under-or over-dispersed relative to the Poisson distribution. The normalizing constant Z ($\lambda$, $\nu$) is given by an infinite series that in general has no closed form, although several papers have derived approximations for this sum. In this work, we start by using probabilistic argument to obtain the leading term in the asymptotic expansion of Z ($\lambda$, $\nu$) in the limit $\lambda$ → ∞ that holds for all $\nu$ > 0. We then use an integral representation to obtain the entire asymptotic series and give explicit formulas for the first eight coefficients. We apply this asymptotic series to obtain approximations for the mean, variance, cumulants, skewness, excess kurtosis and raw moments of CMP random variables. Numerical results confirm that these correction terms yield more accurate estimates than those obtained using just the leading-order term.},
author = {Gaunt, Robert E and Iyengar, Satish and {Olde Daalhuis}, Adri B and Simsek, Burcin and {Robert Gaunt}, B E},
doi = {10.1007/s10463-017-0629-6},
journal = {Ann Inst Stat Math},
keywords = {Approximation,Asymptotic series,Conway–Maxwell–Poisson distribution,Generalized hypergeometric function,Normalizing constant,Stein's method},
pages = {163--180},
title = {{An asymptotic expansion for the normalizing constant of the Conway-Maxwell-Poisson distribution}},
url = {https://doi.org/10.1007/s10463-017-0629-6},
volume = {71},
year = {2019}
}
@article{RAUCH1965,
annote = {doi: 10.2514/3.3166},
author = {Rauch, H E and Tung, F and Striebel, C T},
doi = {10.2514/3.3166},
issn = {0001-1452},
journal = {AIAA Journal},
month = {aug},
number = {8},
pages = {1445--1450},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Maximum likelihood estimates of linear dynamic systems}},
url = {https://doi.org/10.2514/3.3166},
volume = {3},
year = {1965}
}
@article{Brown2001,
abstract = {Neural receptive fields are plastic: with experience, neurons in many brain regions change their spiking responses to relevant stimuli. Analysis of receptive field plasticity from experimental measurements is crucial for understanding how neural systems adapt their representations of relevant biological information. Current analysis methods using histogram estimates of spike rate functions in nonoverlapping temporal windows do not track the evolution of receptive field plasticity on a fine time scale. Adaptive signal processing is an established engineering paradigm for estimating time-varying system parameters from experimental measurements. We present an adaptive filter algorithm for tracking neural receptive field plasticity based on point process models of spike train activity. We derive an instantaneous steepest descent algorithm by using as the criterion function the instantaneous log likelihood of a point process spike train model. We apply the point process adaptive filter algorithm in a study of spatial (place) receptive field properties of simulated and actual spike train data from rat CA1 hippocampal neurons. A stability analysis of the algorithm is sketched in the [Appendix][1]. The adaptive algorithm can update the place field parameter estimates on a millisecond time scale. It reliably tracked the migration, changes in scale, and changes in maximum firing rate characteristic of hippocampal place fields in a rat running on a linear track. Point process adaptive filtering offers an analytic method for studying the dynamics of neural receptive fields.

 [1]: #app-1},
author = {Brown, Emery N. and Nguyen, David P. and Frank, Loren M. and Wilson, Matthew A. and Solo, Victor},
doi = {10.1073/PNAS.201409398},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {oct},
number = {21},
pages = {12261--12266},
pmid = {11593043},
publisher = {National Academy of Sciences},
title = {{An analysis of neural receptive field plasticity by point process adaptive filtering}},
url = {https://www.pnas.org/content/98/21/12261},
volume = {98},
year = {2001}
}
@article{Tomko1974,
abstract = {The variability in the response of cortical neurons to identical visual stimuli was examined from 185 visual cortical neurons. The results indicate that the number of spike discharges during short latency phasic excitatory responses satisfied a Poisson distribution. One group of corticalneurons with spontaneous frequencies between 7 and 12 spikes/sec (s/s) exhibited non-stationary response properties during long latency on-responses. It is proposed that non-stationary post-stimulus responses may indicate the presence of dynamic feature-detecting mechanisms in visual cortex. {\textcopyright} 1974.},
author = {Tomko, George J and Crapper, Donald R},
doi = {10.1016/0006-8993(74)90438-7},
isbn = {0006-8993},
issn = {00068993},
journal = {Brain Research},
number = {3},
pages = {405--418},
pmid = {4422918},
title = {{Neuronal variability: non-stationary responses to identical visual stimuli}},
volume = {79},
year = {1974}
}
@article{Maimon2009,
abstract = {Cortical areas differ in their patterns of connectivity, cellular composition, and functional architecture. Spike trains, on the other hand, are commonly assumed to follow similarly irregular dynamics across neocortex. We examined spike-time statistics in four parietal areas using a method that accounts for nonstationarities in firing rate. We found that, whereas neurons in visual areas fire irregularly, many cells in association and motor-like parietal regions show increasingly regular spike trains by comparison. Regularity was evident both in the shape of interspike interval distributions and in spike-count variability across trials. Thus, Poisson-like randomness is not a universal feature of neocortex. Rather, many parietal cells have reduced trial-to-trial variability in spike counts that could provide for more reliable firing-rate signals. These results suggest that spiking dynamics may play different roles in different cortical areas and should not be assumed to arise from fundamentally irreducible noise sources. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Maimon, Gaby and Assad, John a.},
doi = {10.1016/j.neuron.2009.03.021},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
keywords = {SYSBIO},
number = {3},
pages = {426--440},
pmid = {19447097},
publisher = {Elsevier},
title = {{Beyond Poisson: Increased Spike-Time Regularity across Primate Parietal Cortex}},
volume = {62},
year = {2009}
}
@article{Amarasingham2006,
abstract = {The variability of cortical activity in response to repeated presentations of a stimulus has been an area of controversy in the ongoing debate regarding the evidence for fine temporal structure in nervous system activity. We present a new statistical technique for assessing the significance of observed variability in the neural spike counts with respect to a minimal Poisson hypothesis, which avoids the conventional but troubling assumption that the spiking process is identically distributed across trials. We apply the method to recordings of inferotemporal cortical neurons of primates presented with complex visual stimuli. On this data, the minimal Poisson hypothesis is rejected: the neuronal responses are too reliable to be fit by a typical firing-rate model, even allowing for sudden, time-varying, and trial-dependent rate changes after stimulus onset. The statistical evidence favors a tightly regulated stimulus response in these neurons, close to stimulus onset, although not further away.},
author = {Amarasingham, Asohan and Chen, Ting Li and Geman, Stuart and Harrison, Matthew T. and Sheinberg, David L.},
doi = {10.1523/JNEUROSCI.2948-05.2006},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Inferotemporal cortex,Non-poisson spiking,Object recognition,Poisson hypothesis test,Regularity,Spike train analysis,Spike trains,Temporal coding,Trial-to-trial variability,Vision},
month = {jan},
number = {3},
pages = {801--809},
pmid = {16421300},
publisher = {Society for Neuroscience},
title = {{Spike Count Reliability and the Poisson Hypothesis}},
url = {https://www.jneurosci.org/content/26/3/801 https://www.jneurosci.org/content/26/3/801.abstract},
volume = {26},
year = {2006}
}
@article{DeWeese2003,
abstract = {Neurons are often assumed to operate in a highly unreliable manner: a neuron can signal the same stimulus with a variable number of action potentials. However, much of the experimental evidence supporting this view was obtained in the visual cortex. We have, therefore, assessed trial-to-trial variability in the auditory cortex of the rat. To ensure single-unit isolation, we used cell-attached recording. Tone-evoked responses were usually transient, often consisting of, on average, only a single spike per stimulus. Surprisingly, the majority of responses were not just transient, but were also binary, consisting of 0 or 1 action potentials, but not more, in response to each stimulus; several dramatic examples consisted of exactly one spike on 100% of trials, with no trial-to-trial variability in spike count. The variability of such binary responses differs from comparably transient responses recorded in visual cortical areas such as area MT, and represent the lowest trial-to-trial variability mathematically possible for responses of a given firing rate. Our study thus establishes for the first time that transient responses in auditory cortex can be described as a binary process, rather than as a highly variable Poisson process. These results demonstrate that cortical architecture can support a more precise control of spike number than was previously recognized, and they suggest a re-evaluation of models of cortical processing that assume noisiness to be an inevitable feature of cortical codes.},
author = {DeWeese, Michael R and Wehr, Michael and Zador, Anthony M},
doi = {23/21/7940 [pii]},
isbn = {1529-2401 (Electronic)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
number = {21},
pages = {7940--7949},
pmid = {12944525},
title = {{Binary spiking in auditory cortex.}},
volume = {23},
year = {2003}
}
@article{Kara2000,
abstract = {The response of a cortical cell to a repeated stimulus can be highly variable from one trial to the next. Much lower variability has been reported of retinal cells. We recorded visual responses simultaneously from three successive stages of the cat visual system: retinal ganglion cells (RGCs), thalamic (LGN) relay cells, and simple cells in layer 4 of primary visual cortex. Spike count variability was lower than that of a Poisson process at all three stages but increased at each stage. Absolute and relative refractory periods largely accounted for the reliability at all three stages. Our results show that cortical responses can be more reliable than previously thought. The differences in reliability in retina, LGN, and cortex can be explained by (1) decreasing firing rates and (2) decreasing absolute and relative refractory periods.},
author = {Kara, P and Reinagel, P and Reid, R C},
doi = {10.1016/S0896-6273(00)00072-6},
isbn = {0896-6273 (Print)\n0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {3},
pages = {635--646},
pmid = {11055444},
title = {{Low response variability in simultaneously recorded retinal, thalamic, and cortical neurons.}},
volume = {27},
year = {2000}
}
@article{Churchland2006,
author = {Churchland, M M and Yu, B M and Ryu, S I and Santhanam, G and Shenoy, K V},
journal = {Journal of Neuroscience},
number = {14},
pages = {3697},
title = {{Neural Variability in Premotor Cortex Provides a Signature of Motor Preparation}},
volume = {26},
year = {2006}
}
@article{Czanner2008,
abstract = {Recording single-neuron activity from a specific brain region across multiple trials in response to the same stimulus or execution of the same behavioral task is a common neurophysiology protocol. The raster plots of the spike trains often show strong between-trial and within-trial dynamics, yet the standard analysis of these data with the peristimulus time histogram (PSTH) and ANOVA do not consider between-trial dynamics. By itself, the PSTH does not provide a framework for statistical inference. We present a state-space generalized linear model (SS-GLM) to formulate a point process representation of between-trial and within-trial neural spiking dynamics. Our model has the PSTH as a special case. We provide a framework for model estimation, model selection, goodness-of-fit analysis, and inference. In an analysis of hippocampal neural activity recorded from a monkey performing a location-scene association task, we demonstrate how the SS-GLM may be used to answer frequently posed neurophysiological questions including, What is the nature of the between-trial and within-trial task-specific modulation of the neural spiking activity? How can we characterize learning-related neural dynamics? What are the timescales and characteristics of the neuron's biophysical properties? Our results demonstrate that the SS-GLM is a more informative tool than the PSTH and ANOVA for analysis of multiple trial neural responses and that it provides a quantitative characterization of the between-trial and withintrial neural dynamics readily visible in raster plots, as well as the less apparent fast (1-10 ms), intermediate (11-20 ms), and longer (>20 ms) timescale features of the neuron's biophysical properties.},
author = {Czanner, Gabriela and Eden, Uri T and Wirth, Sylvia and Yanike, Marianna and Suzuki, Wendy A and Brown, Emery N},
doi = {10.1152/jn.00343.2007},
journal = {Journal of Neurophysiology},
number = {5},
pages = {2672--2693},
title = {{Analysis of between-trial and within-trial neural spiking dynamics}},
volume = {99},
year = {2008}
}
@article{Smith2003,
abstract = {A widely used signal processing paradigm is the state-space model. The state-space model is defined by two equations: an observation equation that describes how the hidden state or latent process is observed and a state equation that defines the evolution of the process through time. Inspired by neurophysiology experiments in which neural spiking activity is induced by an implicit (latent) stimulus, we develop an algorithm to estimate a state-space model observed through point process measurements. We represent the latent process modulating the neural spiking activity as a gaussian autoregressive model driven by an external stimulus. Given the latent process, neural spiking activity is characterized as a general point process defined by its conditional intensity function. We develop an approximate expectation-maximization (EM) algorithm to estimate the unobservable state-space process, its parameters, and the parameters of the point process. The EM algorithm combines a point process recursive nonlinear filter algorithm, the fixed interval smoothing algorithm, and the state-space covariance algorithm to compute the complete data log likelihood efficiently. We use a Kolmogorov-Smirnov test based on the time-rescaling theorem to evaluate agreement between the model and point process data. We illustrate the model with two simulated data examples: an ensemble of Poisson neurons driven by a common stimulus and a single neuron whose conditional intensity function is approximated as a local Bernoulli process.},
author = {Smith, Anne C. and Brown, Emery N.},
doi = {10.1162/089976603765202622},
issn = {08997667},
journal = {Neural Computation},
month = {may},
number = {5},
pages = {965--991},
pmid = {12803953},
publisher = { MIT Press  238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu  },
title = {{Estimating a state-space model from point process observations}},
url = {https://www.mitpressjournals.org/doix/abs/10.1162/089976603765202622},
volume = {15},
year = {2003}
}
@techreport{Gao2015,
abstract = {Latent factor models have been widely used to analyze simultaneous recordings of spike trains from large, heterogeneous neural populations. These models assume the signal of interest in the population is a low-dimensional latent intensity that evolves over time, which is observed in high dimension via noisy point-process observations. These techniques have been well used to capture neural correlations across a population and to provide a smooth, denoised, and concise representation of high-dimensional spiking data. One limitation of many current models is that the observation model is assumed to be Poisson, which lacks the flexibility to capture under-and over-dispersion that is common in recorded neural data, thereby introducing bias into estimates of covariance. Here we develop the generalized count linear dynamical system, which relaxes the Poisson assumption by using a more general exponential family for count data. In addition to containing Poisson, Bernoulli, negative binomial, and other common count distributions as special cases, we show that this model can be tractably learned by extending recent advances in variational inference techniques. We apply our model to data from primate motor cortex and demonstrate performance improvements over state-of-the-art methods, both in capturing the variance structure of the data and in held-out prediction.},
author = {Gao, Yuanjun and Buesing, Lars and Shenoy, Krishna V and Cunningham, John P},
booktitle = {Advances in Neural Information Processing Systems},
pages = {2044--2052},
title = {{High-dimensional neural spike train analysis with generalized count linear dynamical systems}},
volume = {28},
year = {2015}
}
@techreport{Pillow2012,
abstract = {Characterizing the information carried by neural populations in the brain requires accurate statistical models of neural spike responses. The negative-binomial distribution provides a convenient model for over-dispersed spike counts, that is, responses with greater-than-Poisson variability. Here we describe a powerful data-augmentation framework for fully Bayesian inference in neural models with negative-binomial spiking. Our approach relies on a recently described latent-variable representation of the negative-binomial distribution, which equates it to a Polya-gamma mixture of normals. This framework provides a tractable, conditionally Gaussian representation of the posterior that can be used to design efficient EM and Gibbs sampling based algorithms for inference in regression and dynamic factor models. We apply the model to neural data from primate retina and show that it substantially outperforms Poisson regression on held-out data, and reveals latent structure underlying spike count correlations in simultaneously recorded spike trains.},
author = {Pillow, Jonathan W. and Scott, James G},
booktitle = {Advances in Neural Information Processing Systems},
pages = {1898--1906},
title = {{Fully Bayesian inference for neural models with negative-binomial spiking}},
volume = {25},
year = {2012}
}
@article{Dragoi2000,
abstract = {A key emergent property of the primary visual cortex (V1) is the orientation selectivity of its neurons. The extent to which adult visual cortical neurons can exhibit changes in orientation selectivity is unknown. Here we use single-unit recording and intrinsic signal imaging in V1 of adult cats to demonstrate systematic repulsive shifts in orientation preference following short-term exposure (adaptation) to one stimulus orientation. In contrast to the common view of adaptation as a passive process by which responses around the adapting orientation are reduced, we show that changes in orientation tuning also occur due to response increases at orientations away from the adapting stimulus. Adaptation-induced orientation plasticity is thus an active time-dependent process that involves network interactions and includes both response depression and enhancement.},
author = {Dragoi, Valentin and Sharma, Jitendra and Sur, Mriganka},
doi = {10.1016/S0896-6273(00)00103-3},
issn = {0896-6273},
journal = {Neuron},
month = {oct},
number = {1},
pages = {287--298},
pmid = {11087001},
publisher = {Cell Press},
title = {{Adaptation-Induced Plasticity of Orientation Tuning in Adult Visual Cortex}},
volume = {28},
year = {2000}
}
@misc{Kohn2016,
author = {Kohn, A. and Smith, M.A.},
booktitle = {CRCNS.org},
title = {{Utah array extracellular recordings of spontaneous and visually evoked activity from anesthetized macaque primary visual cortex (V1)}},
url = {http://dx.doi.org/10.6080/K0NC5Z4X},
year = {2016}
}
@article{Shoham2003,
abstract = {A number of recent methods developed for automatic classification of multiunit neural activity rely on a Gaussian model of the variability of individual waveforms and the statistical methods of Gaussian mixture decomposition. Recent evidence has shown that the Gaussian model does not accurately capture the multivariate statistics of the waveform samples' distribution. We present further data demonstrating non-Gaussian statistics, and show that the multivariate t-distribution, a wide-tailed family of distributions, provides a significantly better fit to the true statistics. We introduce an adaptation of a new expectation-maximization based competitive mixture decomposition algorithm and show that it efficiently and reliably performs mixture decomposition of t-distributions. Our algorithm determines the number of units in multiunit neural recordings, even in the presence of significant noise contamination resulting from random threshold crossings and overlapping spikes. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {Shoham, Shy and Fellows, Matthew R. and Normann, Richard A.},
doi = {10.1016/S0165-0270(03)00120-1},
issn = {0165-0270},
journal = {Journal of neuroscience methods},
keywords = {Action Potentials / physiology*,Animals,Cluster Analysis,Comparative Study,Computer Simulation,Electrophysiology,MEDLINE,Macaca mulatta,Matthew R Fellows,Models,Motor Cortex / physiology*,Multivariate Analysis*,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neurological,Neurons / physiology*,Non-U.S. Gov't,Normal Distribution,P.H.S.,PubMed Abstract,Research Support,Richard A Normann,Shy Shoham,Statistical,U.S. Gov't,doi:10.1016/s0165-0270(03)00120-1,pmid:12906941},
month = {aug},
number = {2},
pages = {111--122},
pmid = {12906941},
publisher = {J Neurosci Methods},
title = {{Robust, automatic spike sorting using mixtures of multivariate t-distributions}},
url = {https://pubmed.ncbi.nlm.nih.gov/12906941/},
volume = {127},
year = {2003}
}
@article{Kelly2010,
abstract = {Multineuronal recordings have revealed that neurons in primary visual cortex (V1) exhibit coordinated fluctuations of spiking activity in the absence and in the presence of visual stimulation. From the perspective of understanding a single cell's spiking activity relative to a behavior or stimulus, these network fluctuations are typically considered to be noise. We show that these events are highly correlated with another commonly recorded signal, the local field potential (LFP), and are also likely related to global network state phenomena which have been observed in a number of neural systems. Moreover, we show that attributing a component of cell firing to these network fluctuations via explicit modeling of the LFP improves the recovery of cell properties. This suggests that the impact of network fluctuations may be estimated using the LFP, and that a portion of this network activity is unrelated to the stimulus and instead reflects ongoing cortical activity. Thus, the LFP acts as an easily accessible bridge between the network state and the spiking activity. {\textcopyright} Springer Science+Business Media, LLC 2010.},
author = {Kelly, Ryan C. and Smith, Matthew A. and Kass, Robert E. and Lee, Tai Sing},
doi = {10.1007/S10827-009-0208-9},
issn = {09295313},
journal = {Journal of Computational Neuroscience},
keywords = {Correlation,Decoding,Local field potential,Multielectrode array,Network state,Population coding,Spontaneous activity},
month = {dec},
number = {3},
pages = {567--579},
pmid = {20094906},
title = {{Local field potentials indicate network state and account for neuronal response variability}},
volume = {29},
year = {2010}
}
@article{Smith2008,
abstract = {The spiking activity of cortical neurons is correlated. For instance, trial-to-trial fluctuations in response strength are shared between neurons, and spikes often occur synchronously. Understanding the properties and mechanisms that generate these forms of correlation is critical for determining their role in cortical processing. We therefore investigated the spatial extent and functional specificity of correlated spontaneous and evoked activity. Because feedforward, recurrent, and feedback pathways have distinct extents and specificity, we reasoned that these measurements could elucidate the contribution of each type of input. We recorded single unit activity with microelectrode arrays which allowed us to measure correlation in many hundreds of pairings, across a large range of spatial scales. Our data show that correlated evoked activity is generated by two mechanisms that link neurons with similar orientation preferences on different spatial scales: one with high temporal precision and a limited spatial extent (∼3 mm), and a second that gives rise to correlation on a slow time scale and extends as far as we were able to measure (10 mm). The former is consistent with common input provided by horizontal connections; the latter likely involves feedback from extrastriate cortex. Spontaneous activity was correlated over a similar spatial extent, but approximately twice as strongly as evoked activity. Visual stimuli thus caused a substantial decrease in correlation, particularly at response onset. These properties and the circuit mechanism they imply provide new constraints on the functional role that correlation may play in visual processing. Copyright {\textcopyright} 2008 Society for Neuroscience.},
author = {Smith, Matthew A. and Kohn, Adam},
doi = {10.1523/JNEUROSCI.2929-08.2008},
issn = {02706474},
journal = {Journal of Neuroscience},
keywords = {Array,Cross-correlogram,Multielectrode recordings,Noise correlation,Population coding,Signal correlation,Spontaneous activity,Synchrony},
month = {nov},
number = {48},
pages = {12591--12603},
pmid = {19036953},
title = {{Spatial and temporal scales of neuronal correlation in primary visual cortex}},
volume = {28},
year = {2008}
}
@article{Mizuseki2013,
author = {Mizuseki, K. and Sirota, A. and Pastalkova, E. and Diba, K. and Buzs{\'{a}}ki, G.},
journal = {CRCNS.org},
title = {{Multiple single unit recordings from different rat hippocampal and entorhinal regions while the animals were performing multiple behavioral tasks}},
url = {http://dx.doi.org/10.6080/K09G5JRZ},
year = {2013}
}
@article{Rossant2016,
abstract = {Silicon microelectrodes are a powerful technique for recording neuronal population activity. Increases in probe size and density make for larger recordable populations, but also require new techniques for processing the resulting data. The authors describe a suite of practical, open source software for spike sorting of large, dense electrode arrays. Developments in microfabrication technology have enabled the production of neural electrode arrays with hundreds of closely spaced recording sites, and electrodes with thousands of sites are under development. These probes in principle allow the simultaneous recording of very large numbers of neurons. However, use of this technology requires the development of techniques for decoding the spike times of the recorded neurons from the raw data captured from the probes. Here we present a set of tools to solve this problem, implemented in a suite of practical, user-friendly, open-source software. We validate these methods on data from the cortex, hippocampus and thalamus of rat, mouse, macaque and marmoset, demonstrating error rates as low as 5%.},
author = {Rossant, Cyrille and Kadir, Shabnam N. and Goodman, Dan F.M. and Schulman, John and Hunter, Maximilian L.D. and Saleem, Aman B. and Grosmark, Andres and Belluscio, Mariano and Denfield, George H. and Ecker, Alexander S. and Tolias, Andreas S. and Solomon, Samuel and Buzski, Gy{\"{o}}rgy and Carandini, Matteo and Harris, Kenneth D.},
doi = {10.1038/nn.4268},
issn = {1546-1726},
journal = {Nature Neuroscience 2016 19:4},
keywords = {Neural decoding,Software},
month = {mar},
number = {4},
pages = {634--641},
pmid = {26974951},
publisher = {Nature Publishing Group},
title = {{Spike sorting for large, dense electrode arrays}},
url = {https://www.nature.com/articles/nn.4268},
volume = {19},
year = {2016}
}
@article{Mizuseki2014,
abstract = {Using silicon-based recording electrodes, we recorded neuronal activity of the dorsal hippocampus and dorsomedial entorhinal cortex from behaving rats. The entorhinal neurons were classified as principal neurons and interneurons based on monosynaptic interactions and wave-shapes. The hippocampal neurons were classified as principal neurons and interneurons based on monosynaptic interactions, wave-shapes and burstiness. The data set contains recordings from 7,736 neurons (6,100 classified as principal neurons, 1,132 as interneurons, and 504 cells that did not clearly fit into either category) obtained during 442 recording sessions from 11 rats (a total of 204.5 hours) while they were engaged in one of eight different behaviours/tasks. Both original and processed data (time stamp of spikes, spike waveforms, result of spike sorting and local field potential) are included, along with metadata of behavioural markers. Community-driven data sharing may offer cross-validation of findings, refinement of interpretations and facilitate discoveries.},
author = {Mizuseki, Kenji and Diba, Kamran and Pastalkova, Eva and Teeters, Jeff and Sirota, Anton and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.12688/f1000research.3895.2},
issn = {1759796X},
journal = {F1000Research 2014 3:98},
month = {jul},
pages = {98},
publisher = {F1000 Research Limited},
title = {{Neurosharing: large-scale data sets (spike, LFP) recorded from the hippocampal-entorhinal system in behaving rats}},
url = {https://f1000research.com/articles/3-98},
volume = {3},
year = {2014}
}
@article{Deweese2004,
abstract = {The high variability of cortical sensory responses is often assumed to impose a major constraint on efficient computation. In the auditory cortex, however, response variability can be very low. We have used in vivo whole cell patch-clamp methods to study the trial-to-trial variability of the subthreshold fluctuations in membrane potential underlying tone-evoked responses in the auditory cortex of anesthetized rats. Using methods adapted from classical quantal analysis, we partitioned this subthreshold variability into a private component (which includes synaptic, thermal, and other sources local to the recorded cell) and a shared component arising from network interactions. Here we report that this private component is remarkably small, usually about 1-3 mV, as quantified by the variance divided by the mean of the ensemble of tone-evoked response heights. The shared component can be much larger, and shows more heterogeneity across the population, ranging from about 0 to 10 mV. The remarkable fact that, at least 5 synapses from the auditory periphery, this variability remains so small raises the possibility that the intervening neural circuitry is organized so as to prevent private noise from accumulating as neural signals propagate to the cortex.},
author = {Deweese, Michael R and Zador, Anthony M},
doi = {10.1152/jn.00197.2004},
isbn = {0022-3077 (Print)},
issn = {0022-3077},
journal = {Journal of neurophysiology},
number = {3},
pages = {1840--1855},
pmid = {15115790},
title = {{Shared and private variability in the auditory cortex.}},
volume = {92},
year = {2004}
}
@article{Taouali2016,
abstract = {The repeated presentation of an identical visual stimulus in the receptive field of a neuron may evoke different spiking patterns at each trial. Probabilistic methods are essential to understand the functional role of this variance within the neural activity. In that case, a Poisson process is the most common model of trial-to-trial variability. For a Poisson process, the variance of the spike count is constrained to be equal to the mean, irrespective of the duration of measurements. Numerous studies have shown that this relationship does not generally hold. Specifically, a majority of electrophysiological recordings show an "overdispersion" effect: responses that exhibit more intertrial variability than expected from a Poisson process alone. A model that is particularly well suited to quantify overdispersion is the Negative-Binomial distribution model. This model is well-studied and widely used but has only recently been applied to neuroscience. In this article, we address three main issues. First, we describe how the Negative-Binomial distribution provides a model apt to account for overdispersed spike counts. Second, we quantify the significance of this model for any neurophysiological data by proposing a statistical test, which quantifies the odds that overdispersion could be due to the limited number of repetitions (trials). We apply this test to three neurophysiological data sets along the visual pathway. Finally, we compare the performance of this model to the Poisson model on a population decoding task. We show that the decoding accuracy is improved when accounting for overdispersion, especially under the hypothesis of tuned overdispersion.},
author = {Taouali, Wahiba and Benvenuti, Giacomo and Wallisch, Pascal and Chavane, Fr{\'{e}}d{\'{e}}ric and Perrinet, Laurent U},
doi = {10.1152/jn.00194.2015},
issn = {1522-1598},
journal = {Journal of neurophysiology},
month = {jan},
number = {1},
pages = {434--44},
pmid = {26445864},
title = {{Testing the odds of inherent vs. observed overdispersion in neural spike counts.}},
volume = {115},
year = {2016}
}
@article{Wu2008,
author = {Wu, W and Hatsopoulos, N G},
isbn = {1534-4320},
journal = {Neural Systems and Rehabilitation Engineering, IEEE Transactions on},
number = {3},
pages = {213--222},
publisher = {IEEE},
title = {{Real-time decoding of nonstationary neural activity in motor cortex}},
volume = {16},
year = {2008}
}
@article{Stevenson2011a,
abstract = {In systems neuroscience, neural activity that represents movements or sensory stimuli is often characterized by spatial tuning curves that may change in response to training, attention, altered mechanics, or the passage of time. A vital step in determining whether tuning curves change is accounting for estimation uncertainty due to measurement noise. In this study, we address the issue of tuning curve stability using methods that take uncertainty directly into account. We analyze data recorded from neurons in primary motor cortex using chronically implanted, multielectrode arrays in four monkeys performing center-out reaching. With the use of simulations, we demonstrate that under typical experimental conditions, the effect of neuronal noise on estimated preferred direction can be quite large and is affected by both the amount of data and the modulation depth of the neurons. In experimental data, we find that after taking uncertainty into account using bootstrapping techniques, the majority of neurons appears to be very stable on a timescale of minutes to hours. Lastly, we introduce adaptive filtering methods to explicitly model dynamic tuning curves. In contrast to several previous findings suggesting that tuning curves may be in constant flux, we conclude that the neural representation of limb movement is, on average, quite stable and that impressions to the contrary may be largely the result of measurement noise. {\textcopyright} 2011 the American Physiological Society.},
author = {Stevenson, Ian H. and Cherian, Anil and London, Brian M. and Sachs, Nicholas A. and Lindberg, Eric and Reimer, Jacob and Slutzky, Marc W. and Hatsopoulos, Nicholas G. and Miller, Lee E. and Kording, Konrad P.},
doi = {10.1152/jn.00626.2010},
issn = {00223077},
journal = {Journal of Neurophysiology},
keywords = {Neurons,Poisson noise,Primary motor cortex,Sensory stimuli,Spatial tuning curves,Tuning curves},
month = {aug},
number = {2},
pages = {764--774},
pmid = {21613593},
publisher = {J Neurophysiol},
title = {{Statistical assessment of the stability of neural movement representations}},
url = {https://pubmed.ncbi.nlm.nih.gov/21613593/},
volume = {106},
year = {2011}
}
@article{Stevenson2018,
abstract = {Generalized linear models (GLMs) have a wide range of applications in systems neuroscience describing the encoding of stimulus and behavioral variables, as well as the dynamics of single neurons. However, in any given experiment, many variables that have an impact on neural activity are not observed or not modeled. Here we demonstrate, in both theory and practice, how these omitted variables can result in biased parameter estimates for the effects that are included. In three case studies, we estimate tuning functions for common experiments in motor cortex, hippocampus, and visual cortex. We find that including traditionally omitted variables changes estimates of the original parameters and that modulation originally attributed to one variable is reduced after new variables are included. In GLMs describing single-neuron dynamics, we then demonstrate how postspike history effects can also be biased by omitted variables. Here we find that omitted variable bias can lead to mistaken conclusions about the stability of single-neuron firing. Omitted variable bias can appear in any model with confounders?where omitted variables modulate neural activity and the effects of the omitted variables covary with the included effects. Understanding how and to what extent omitted variable bias affects parameter estimates is likely to be important for interpreting the parameters and predictions of many neural encoding models.},
annote = {doi: 10.1162/neco_a_01138},
author = {Stevenson, Ian H.},
doi = {10.1162/neco_a_01138},
issn = {0899-7667},
journal = {Neural Computation},
month = {oct},
number = {12},
pages = {3227--3258},
publisher = {MIT Press},
title = {{Omitted Variable Bias in GLMs of Neural Spiking Activity}},
url = {https://doi.org/10.1162/neco_a_01138},
volume = {30},
year = {2018}
}
@article{DelCastillo2005,
abstract = {We consider a wide set of statistical models that extend the Poisson distribution. These models are obtained through weighted versions of the Poisson family and can be approximated by a log-linear model. Under general conditions, we prove that the new models contain overdispersed and underdispersed distributions and that they can be parametrized with the mean and variance. A classical data set is analyzed to show the usefulness of the new models. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {del Castillo, Joan and P{\'{e}}rez-Casany, Marta},
doi = {10.1016/J.JSPI.2004.04.019},
issn = {0378-3758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Exponential models,Index of dispersion,Stochastic orders,Weighted distributions,Zero-inflated distributions},
month = {oct},
number = {2},
pages = {486--500},
publisher = {North-Holland},
title = {{Overdispersed and underdispersed Poisson generalizations}},
volume = {134},
year = {2005}
}


